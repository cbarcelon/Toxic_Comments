{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv\n",
      "Toxic Benchmark-checkpoint.ipynb\n",
      "Toxic_Comments_Capstone.ipynb\n",
      "Toxic_Comments_Sequential_LSTM.ipynb\n",
      "Toxic_self_benchmarking.ipynb\n",
      "train.csv\n",
      "weights_base.best.hdf5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "max_features = 30000\n",
    "maxlen = 200\n",
    "\n",
    "df = pd.read_csv(\"./train.csv\")\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "list_sentences_train = train[\"comment_text\"].fillna(\"cbarcelon\").values\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values\n",
    "list_sentences_test = test[\"comment_text\"].fillna(\"cbarcelon\").values\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "X_t = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_te = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    embed_size = 512\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size)(inp)\n",
    "    x = Bidirectional(LSTM(200, return_sequences=True))(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(0.7)(x)\n",
    "    x = Dense(200, activation=\"relu\")(x)\n",
    "    x = Dropout(0.7)(x)\n",
    "    x = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 512)          15360000  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200, 400)          1140800   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1206      \n",
      "=================================================================\n",
      "Total params: 16,582,206\n",
      "Trainable params: 16,582,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69012 samples, validate on 7668 samples\n",
      "Epoch 1/10\n",
      "69000/69012 [============================>.] - ETA: 0s - loss: 0.1599 - acc: 0.9552Epoch 00000: val_loss improved from inf to 0.08526, saving model to weights_base.best.hdf5\n",
      "69012/69012 [==============================] - 185s - loss: 0.1599 - acc: 0.9552 - val_loss: 0.0853 - val_acc: 0.9727\n",
      "Epoch 2/10\n",
      "69000/69012 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9744Epoch 00001: val_loss improved from 0.08526 to 0.05595, saving model to weights_base.best.hdf5\n",
      "69012/69012 [==============================] - 184s - loss: 0.0733 - acc: 0.9744 - val_loss: 0.0560 - val_acc: 0.9808\n",
      "Epoch 3/10\n",
      "69000/69012 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9806Epoch 00002: val_loss did not improve\n",
      "69012/69012 [==============================] - 184s - loss: 0.0538 - acc: 0.9806 - val_loss: 0.0575 - val_acc: 0.9816\n",
      "Epoch 4/10\n",
      "69000/69012 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9821Epoch 00003: val_loss did not improve\n",
      "69012/69012 [==============================] - 183s - loss: 0.0474 - acc: 0.9821 - val_loss: 0.0590 - val_acc: 0.9826\n",
      "Epoch 5/10\n",
      "69000/69012 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9845Epoch 00004: val_loss did not improve\n",
      "69012/69012 [==============================] - 183s - loss: 0.0410 - acc: 0.9845 - val_loss: 0.0573 - val_acc: 0.9821\n",
      "Epoch 6/10\n",
      "69000/69012 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9855Epoch 00005: val_loss did not improve\n",
      "69012/69012 [==============================] - 182s - loss: 0.0378 - acc: 0.9855 - val_loss: 0.0616 - val_acc: 0.9813\n",
      "Epoch 7/10\n",
      "69000/69012 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9863Epoch 00006: val_loss did not improve\n",
      "69012/69012 [==============================] - 182s - loss: 0.0354 - acc: 0.9863 - val_loss: 0.0629 - val_acc: 0.9803\n",
      "Epoch 8/10\n",
      "69000/69012 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9867Epoch 00007: val_loss did not improve\n",
      "69012/69012 [==============================] - 182s - loss: 0.0345 - acc: 0.9867 - val_loss: 0.0735 - val_acc: 0.9806\n",
      "Epoch 9/10\n",
      "69000/69012 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9874Epoch 00008: val_loss did not improve\n",
      "69012/69012 [==============================] - 182s - loss: 0.0329 - acc: 0.9874 - val_loss: 0.0689 - val_acc: 0.9818\n",
      "Epoch 10/10\n",
      "69000/69012 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9879Epoch 00009: val_loss did not improve\n",
      "69012/69012 [==============================] - 182s - loss: 0.0316 - acc: 0.9879 - val_loss: 0.0713 - val_acc: 0.9791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fecb01e7e10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "batch_size = 500\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "file_path=\"weights_base.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)\n",
    "\n",
    "\n",
    "callbacks_list = [checkpoint, early] #early\n",
    "model.fit(X_t, y, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(file_path)\n",
    "y_test = model.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "def calc_loss(y_true, y_pred):\n",
    "    return np.mean([log_loss(y_true[:, i], y_pred[:, i]) \n",
    "                    for i in range(y_true.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19171, 6)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19171, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95258</th>\n",
       "      <td>993803407001</td>\n",
       "      <td>Maybe he should leave e.g. to FC Mars, but I'm...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36738</th>\n",
       "      <td>383075159232</td>\n",
       "      <td>Are you defending Peter or not?  Since your co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92937</th>\n",
       "      <td>969939490051</td>\n",
       "      <td>\"\\n\\n WOW!!!! You edited the comment making me...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64725</th>\n",
       "      <td>674422717410</td>\n",
       "      <td>\"\\nI think the location is fine. The material ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39293</th>\n",
       "      <td>410340345798</td>\n",
       "      <td>Fuck off and die you old timer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "95258  993803407001  Maybe he should leave e.g. to FC Mars, but I'm...      1   \n",
       "36738  383075159232  Are you defending Peter or not?  Since your co...      0   \n",
       "92937  969939490051  \"\\n\\n WOW!!!! You edited the comment making me...      1   \n",
       "64725  674422717410  \"\\nI think the location is fine. The material ...      0   \n",
       "39293  410340345798                     Fuck off and die you old timer      1   \n",
       "\n",
       "       severe_toxic  obscene  threat  insult  identity_hate  \n",
       "95258             0        1       0       0              0  \n",
       "36738             0        0       0       0              0  \n",
       "92937             0        0       0       0              0  \n",
       "64725             0        0       0       0              0  \n",
       "39293             1        1       0       1              0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = calc_loss(test[list_classes].values, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0548385984347\n"
     ]
    }
   ],
   "source": [
    "#score after 1 epoch\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0548385984347\n"
     ]
    }
   ],
   "source": [
    "#score after 4 epochs\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Container.summary of <keras.engine.training.Model object at 0x7f95f8817c18>>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 256)          5120000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 100)          122800    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 5,248,156\n",
      "Trainable params: 5,248,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
