{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Toxic Comments__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chris Barcelon\n",
    "<br>January 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments that are toxic, such as threats, obscenity, insults, and identity-based hate,  are everywhere on the Internet.  The large number of toxic comments have prevented people from participating in discussions they are interested in and they have led to communities either limiting or restricting comments altogether.  A model that is capable of detecting these types of comments could hopefully help online discussions become more productive and respectful.\n",
    "In the paper Ex Machina: Personal Attacks Seen at Scale the authors discuss solving a similar problem initially using logistic regression and multi-layer perceptrons and planned to in the future use LSTM models.  This project is based off the kaggle competition __[Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is to build a model that can detect and classify different types of toxicity in comments.  Given a list of comments the model will predict the probability that each comment is toxic.  It will predict 6 different probabilities one for each 6 different types of toxicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be scored with a column-wise __[log loss](http://www.exegetic.biz/blog/2015/12/making-sense-logarithmic-loss/)__ function.  The score will the be the average of the log loss of each predicted column, where each column is a different type of toxicity.  Log Loss will be used to socre the model because it quantifies the accuracy of a classifier by penalising false classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is a csv file, train.csv, with a large number of Wikipeida comments that have been labeled by humans for toxicity.  Each comment is labled for 6 different types of toxicity: toxic, severe_toxic, obscene, threat, insult, identity_hate.\n",
    "train.csv contains 95850 comments each comment has an id number and a binary classification for each of the types of toxicity.\n",
    "\n",
    "<img src=\"first_10_comments.png\">\n",
    "\n",
    "Of the 95850 comments 9,789 are labeled for at least 1 type of toxicity, meaning the other 86061 comments are not toxic. The number of each comments labeled for each type of toxicity are as follows. \n",
    "- toxic - 9237\n",
    "- severe_toxic: 965\n",
    "- obscene: 5109\n",
    "- threat: 305\n",
    "- insult: 4765\n",
    "- identity_hate: 814\n",
    "<img src=\"Toxic_Comment_Counts.png\">\n",
    "\n",
    "The shortest comment in the dataset is only 1 word and the longest comment is 1403 word.  the average length for a comment is 67 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms and Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NBSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NBSVM(Naive Bayes - Support Vector Machine) is a technique that is often used for text categorization and sentiment analysis.  In the paper __[Baselines and Bigrams: Simple, Good Sentiment and Topic Classification](https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf)__ authors Sida Wang and Christopher D. Manning discuss the use of NBSVM in sentiment classification and topical text classification.  A NBSVM is a model which uses a linear approach on top of naive bayes features.  This model will take use a bag of words approach where each unique word is a feature in the Naive Bayes formula.  This will disregard word order and just look at whether a word appears in each comment and then calculate the probablity that a comment is toxic or not based on words that are in the comment.  The Naive Bayes equation used to calculate the probability is a follows: the **log-count ratio** $r$ for each word $f$ \n",
    "\n",
    "$r = \\log \\frac{\\text{ratio of feature $f$ in non-toxic comments}}{\\text{ratio of feature $f$ in toxic comments}}$\n",
    "\n",
    "where the ratio of feature $f$ in non-toxic comments is the number of times a non-toxic comment has a feature divided by the number of non-toxic comments.\n",
    "This aproach will only give the probability for one type of toxicity at a time so it will be run 6 times one time for each type of toxicity to give a probability for each type of toxicity for each comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Short Term Memory networks (LSTM) are a type of RNN (Recurrent Neural Network).  A RNN is a essentially a neural network on a loop, it can be thought of as multiple copies of the same network where each copy of the network passes some information to the next copy of the network.  This allows the netowrk to preserve data, this preserved data can then be used to help give context to a future data input.  A LSTM is a RNN that is especially good at preserving information over long periods of time.  Christopher Olah used the following diagram to help explain how LSTMs work.\n",
    "\n",
    "<img src=\"LSTM3-chain.png\">\n",
    "\n",
    "**The repeating module in an LSTM contains four interacting layers**\n",
    "\n",
    "<img src=\"LSTM2-notation.png\">\n",
    "\n",
    "In the above diagram, each line carries an entire vector, from the output of one node to the inputs of others. The pink circles represent pointwise operations, like vector addition, while the yellow boxes are learned neural network layers. Lines merging denote concatenation, while a line forking denote its content being copied and the copies going to different locations.\n",
    "\n",
    "To gain a deeper understanding of LSTM networks I recomend reading the full post by Chrisopther Olah __[Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)__\n",
    "\n",
    "While the NBSVM did not care about the word order and used a bag of words for the text, the LSTM network does care about the word order so it will require the text to be vectorized.  Also the LSTM network will be able to calculate the probablilties for each type of toxicity simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benchmark model used is a basic bidirectional LSTM network provided by kaggle user CVxTz.  The kernel used can be found here: __https://www.kaggle.com/CVxTz/keras-bidirectional-lstm-baseline-lb-0-051__\n",
    "A summary of the model used is provided."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_2 (InputLayer)         (None, 100)               0         \n",
    "_________________________________________________________________\n",
    "embedding_2 (Embedding)      (None, 100, 128)          2560000   \n",
    "_________________________________________________________________\n",
    "bidirectional_2 (Bidirection (None, 100, 100)          71600     \n",
    "_________________________________________________________________\n",
    "global_max_pooling1d_2 (Glob (None, 100)               0         \n",
    "_________________________________________________________________\n",
    "dropout_3 (Dropout)          (None, 100)               0         \n",
    "_________________________________________________________________\n",
    "dense_3 (Dense)              (None, 50)                5050      \n",
    "_________________________________________________________________\n",
    "dropout_4 (Dropout)          (None, 50)                0         \n",
    "_________________________________________________________________\n",
    "dense_4 (Dense)              (None, 6)                 306       \n",
    "=================================================================\n",
    "Total params: 2,636,956\n",
    "Trainable params: 2,636,956\n",
    "Non-trainable params: 0\n",
    "_______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When this model was evaluated after 1 epoch, using the predefined log los function it produced a socre of 0.0749. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before any other preprocessing the data was split into 2 sets a training set and a testing set, the testing set is a random 20% of the initial dataset, the training set is the remaining 80% of the data.  The data was split using the sklearn.cross_validation.train_test_split function. \n",
    "\n",
    "To prepare the data for the LSTM model, the text of the comments needed to be converted to sequences to be trained on.  The first thing done to the text was to search through the comments and replace any empty comments with filler text in this case \"cbarcelon\" The text was then converted to sequences using the keras.preprocessing.text.Tokenizer and then to make the training more efficient the sequences were set to a uniform length using the pad_sequences function.  The initial length chosen is 100, 100 was chosen because is above the average length of 67 yet not too long.  It is believed that truncating long comments will not adversely effect the accuracy of the model because most comments will reveal their toxicity within the first 100 words.  To verify this belief different sequence lengths will be tested.\n",
    "\n",
    "To prepare the data for the NBSVM model a bag of words was created.  Using ngrams the text was tokenized and split into words and then was transformed into a matrix of word values. Ngrams are defined as a continuous sequence of items in a sequence.   A sparse matrix was used because most comments only use a small subset of the the total unique words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two algorithms used were implemented separately and then their results were averaged together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NBSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of the NBSVM model was carried out in the jupyter notebook NBSVM_Toxic_Comments.  A summary of the notebook is as follows:\n",
    "- Import the needed libraries and read in the train.csv file using pandas\n",
    "- Split the data set into a train and a test set using train_test_split.\n",
    "- Separate the comment text from their ratings\n",
    "- Transform the comment text into a matrix of word values\n",
    "    - TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize, min_df=11, max_df=0.8, strip_accents='unicode', use_idf=1, smooth_idf=1, sublinear_tf=1)\n",
    "- Define the NBSVMClassifier function\n",
    "    - The basic naive bayes feature equation\n",
    "    \n",
    "    def pr(y_i, y):\n",
    "    \n",
    "    p = x[y==y_i].sum(0)\n",
    "    \n",
    "    return (p+1) / ((y==y_i).sum()+1)\n",
    "- Fit the model to the to training set for each type of toxicity\n",
    "    - model = NbSvmClassifier(C=1, dual=True, n_jobs=-1)   \n",
    "- Predict the ratings based off of the fitted model for eeach type of toxicity.\n",
    "- Check the accuracy of the predictions.\n",
    "- Save the predictions to a csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of the LSTM model was carried out in the jupyter notebook Toxic_Comments_Sequential_LSTM.  Here is a summary of that notebook.\n",
    "- Import the needed libraries and read in the train.csv file using pandas\n",
    "- Split the data into train and test sets using train_test_split.\n",
    "- Separate the comment text from the ratings.\n",
    "- Tokenize the text data into sequences that can be used in the LSTM model.\n",
    "    - The sequences are all set to a length of 100, comments shorter are extended using 0's and longer comments are truncated to a length of 100.\n",
    "- Import a dictioniary of word vectors from GloVe to preweight the words from the comments.\n",
    "    - The word vectors used was trained off of tweets and can be downloaded here __https://nlp.stanford.edu/projects/glove/__\n",
    "- Create a matrix from the downloaded GloVe file using only the words in our dataset.\n",
    "- Define the LSTM model, here is a summary of the model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "embedding_1 (Embedding)      (None, 100, 100)          21033800  \n",
    "_________________________________________________________________\n",
    "bidirectional_1 (Bidirection (None, 100, 400)          481600    \n",
    "_________________________________________________________________\n",
    "average_pooling1d_1 (Average (None, 50, 400)           0         \n",
    "_________________________________________________________________\n",
    "bidirectional_2 (Bidirection (None, 50, 400)           961600    \n",
    "_________________________________________________________________\n",
    "average_pooling1d_2 (Average (None, 25, 400)           0         \n",
    "_________________________________________________________________\n",
    "bidirectional_3 (Bidirection (None, 25, 400)           961600    \n",
    "_________________________________________________________________\n",
    "flatten_1 (Flatten)          (None, 10000)             0         \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 10000)             0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 500)               5000500   \n",
    "_________________________________________________________________\n",
    "dropout_2 (Dropout)          (None, 500)               0         \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 6)                 3006      \n",
    "=================================================================\n",
    "Total params: 28,442,106\n",
    "Trainable params: 28,442,106\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The LSTM model is 3 stacked bidirectional layers and two fully connected dense layers with dropout.\n",
    "- Complie the model \n",
    "    - lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "- Fit the model.\n",
    "    -The model was trained over 4 epochs; more epochs just led to overfitting.\n",
    "- Predict the ratings using the now trained LSTM model\n",
    "- Test the results\n",
    "- Save the results to a csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NBSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To refine the NBSVM model a brute force method was applied to different parameters to find the optimal parameters.  The first parameters tuned were in the TfidfVectorizer, the ngram_range, min_df, and max_df were all optimized.  The ngram_range sets the size of the ngrams used in the bag of words, the min_df is the minimun number of comments that a ngram must appear in order to be used in the model, the max_df is the maximum percent of comments that a ngram can appear in before it is no longer used in the model.  This was done by running the model through nested for loops with 1 parameter being changed each time.  The ngram_range was tested with the value of (1,2) through (1,10), the min_dif with values of 1 through 20, and the max_df with values of .1 through .9.  The min_df and max_df values decide which words to not use in the model either because the words appear in too many comments therefore providing no insight or appearing in too few comments and therefore could not used in generalization.\n",
    "The final paramter refined was the C value in the NBSVMClassifier.  The C value determines how much importance to give to outliers in the data.  C values of 1, 10, 100, 1000 were initially tested with 1 by far producing the best results.  So then the values of 1,2,3,4,5,6 were tested and 1 still provided the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LSTM was refined slowly over many iterations.  This is because the first lstm model implemented was a simple LSTM model similar to one used to benchmark minus the dropout layers.  Once the simple model was working as intended complexity was slowly added.  The first thing added was an additional LSTM layer, this improved the accuracy of the model so another identical layer was added this to improved the accuracy of the model.  After the third lstm layer was added a dense layer was added.  At this point the model was begining to overfit so 2 dropout layers were added.\n",
    "At this stage the model was 3 lstm layers followed by 2 dense layers and before each dense layer a dropout layer.  With the model at this stage the embedding parameters were experimented with.  The embedding layer has multiple parameters that were played with.  The input_dim and output_dim were both increased and decreased.  Eventually an the input_dim was chosen to bed the entire vocabulary of the training comments.  Using a subset of the entire vocabulary allowed the model to be trained much faster but better results were found when using the entire set of vocabulary.  The output dim was set to 100 to match the size of the seqences that were being trained on.\n",
    "Next additional lstm and dense layers were added but they failed to add noticable improvements upon the model so they were then removed.\n",
    "It was at this point that a preweighted dictionary was added.  Upon adding the weights from the GloVe dictionary the models accuracy improved significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the predictions of the NBSVM model are tested using the log loss function it produces a score of 0.051462166523797565.\n",
    "<br>The log loss score of the LSTM model is 0.0464747992263.\n",
    "<br>When the predictions of the two models are averaged together and then tested it results in a score of 0.0466733915127.\n",
    "<br>The benchmark model used produces a score of 0.0749.\n",
    "Using the log loss score the LSTM produces the most accurate predictions of toxicity in given comments and the ensemble of the lstm and nbsvm models procuces a score very close to the lstm's score.  while the nbsvm model gives a significantly worse predictions than the lstm or ensemble.  But still all 3 models produce scores much better than the benchmark lstm model used.\n",
    "\n",
    "The ensemble model was predicted to give the best results but the lstm model was shown to outperform it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check how well the lstm model performed from a practical standpoint examples of clean and toxic comments were looked at individually.\n",
    "<br>For example given the clean comment of\n",
    "<br>\"You claimed to have \"\"scavenged the UN and NGO website for a few hours\"\", yet I found it in minutes by searching for . You are either dishonest or not very thorough.\"\n",
    "<br>The lstm model gave the following probabilties for each type of toxicity.\n",
    "<br>toxic - 1.25816162e-03 \n",
    "<br>severe_toxic - 1.44767694e-06\n",
    "<br>obscene - 8.03762960e-05 \n",
    "<br>threat - 2.61948135e-05\n",
    "<br>insult - 3.63398285e-05\n",
    "<br>identity_hate  - 1.86055913e-05\n",
    "\n",
    "The model was very accurate for this comment.  As seen by the probabilities above the model is very confident that the comment is not toxic\n",
    "\n",
    "<br>Given the toxic comment of\n",
    "<br>\"ameriKKKans like to get their anusses raped\"\n",
    "<br>which is rated as toxic, obscene, insult, and identity_hate\n",
    "<br>The lstm model gave the following predictions\n",
    "<br>toxic - 0.86139816 \n",
    "<br>severe_toxic - 0.02786827\n",
    "<br>obscene - 0.25936157 \n",
    "<br>threat - 0.03552454\n",
    "<br>insult -  0.44790095\n",
    "<br>identity_hate  - 0.08017173\n",
    "\n",
    "While the model is very confident that the model is toxic it is less confident on the other types of toxicity.  It does not predict very well that the comment is identity_hate and obscene. \n",
    "\n",
    "The model does do what it was designed to do but it is still not perfect.  It is a good start at detecting toxicity but it alone is not good enough to moderate a discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free-Form Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Scores.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar chart above shows the log loss scores for each type of toxicity for each model.  Even though the NBSVM has a worse overall score it has a better score when it comes to the threat and identity_hate categories.  This shows that the two models have different strengths.  So depending on the situation one might prefer the NBSVM model.  One such example would be if the owners of a message board were willing to allow obscene comments but still did not want threatening speech or hate speech, in this case the nbsvm model could be considered the better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project can be broken into 2 distinct parts, the NBSVM and LSTM models.  The two models were implemented separately and even though the two models are different they both followed the same general proccess.\n",
    "- Preproccess the text, turn the text into usable form.\n",
    "- Implement a basic form of the prediction model.\n",
    "- Test the results\n",
    "- Improve/add to basic model until it acheives a satisfactory result.\n",
    "\n",
    "One of the parts that I found the most difficult was trying to understand the LSTM model.  I previously did not have any experiance with LSTM models and I discovered that just adding more layers or parameters did not immediately improve the results.\n",
    "One of the most interesting things to me was that the NBSVM model performed as well as it did.  I expected the LSTM model to blow it out of the water when in reality it only performed a little better.  I believe that LSTM models are one of the best ways to determine text sentiment but I do not believe it is good enough to moderate comments unsupervised.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are few ways to improve upon the lstm model.  The easiest way to improve the model would be to give it more data, there is almost an unlimited amount of comments being produced online everyday.  The difficult part is labeling the data for use.  In the absence of additional data two other options come to mind.  The first would be to find a way to reduce overfitting the LSTM model, even with dropout it overfitts very quickly.  Another way to improve the model would be to use the NBSVM model in regards to the threat and identity hate categories and the LSTM model for the other categories."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
